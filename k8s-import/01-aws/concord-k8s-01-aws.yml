# --------------------------------------------------------------------------------------------------------------------
# AWS
# --------------------------------------------------------------------------------------------------------------------

configuration:

  arguments:
    terraformDebug: false
    terraformVersion: 0.12.18
    terraformDirectory: "terraform"
    terraformResources: "terraform-resources"
    terraformResourcesTag: "1.0.0"

flows:

  awsCluster:
    - if: ${clusterRequest.builder.id.equals('eksctl')}
      then:
        - log: "We are building a cluster on ${clusterRequest.provider} using ${clusterRequest.builder.id} ..."
        - awsTerraform
        - eksctlYml
        - eksctlExecution
        # Write the kubeconfig into Concord's secret store and to the agent
        - concordKubeconfig
        # Take the kubeconfig from Concord's secret store and write it into AWS Secrets Manager
        - asmKubeconfig
        - awsIamAuthenticator

  # --------------------------------------------------------------------------------------------------------------------
  # Terraform
  # --------------------------------------------------------------------------------------------------------------------
  # TODO: the terraform processor is general purpose but the configuration below needs to be decoupled from AWS.
  # --------------------------------------------------------------------------------------------------------------------

  awsTerraform:
    - awsTerraformProcessor
    - awsTerraformExecution

  awsTerraformProcessor:

    - ${k8sFileUtils.deleteDirectory(terraformResources)}

    - task: git
      in:
        action: clone
        url: "https://github.com/concord-workflow/concord-terraform.git"
        baseBranch: "${terraformResourcesTag}"
        workingDir: "${terraformResources}"

    - task: terraformProcessor
      in:
        resourceDirectory: "${terraformResources}"
        outputDirectory: "${terraformDirectory}"
        configuration:
          version: "0.12"
          provider: "${clusterRequest.provider}"
          authentication: credentials
          configuration:
            aws_region: "${clusterRequest.region}"
            aws_access_key: "${clusterRequest.aws.accessKey}"
            aws_secret_key: "${clusterRequest.aws.secretKey}"
            tags: ${clusterRequest.aws.tags}
          resources: ${clusterRequest.terraformResources}

  awsTerraformExecution:

    - task: terraform
      in:
        toolVersion: "${terraformVersion}"
        action: apply
        dir: "${terraformDirectory}"
        saveOutput: true
        stateId: ${clusterRequest.clusterId}
        varFiles:
          - "${workDir}/${terraformDirectory}/00.auto.tfvars.json"

  # --------------------------------------------------------------------------------------------------------------------
  # EKSCTL
  # --------------------------------------------------------------------------------------------------------------------
  # TODO: integrate eksctl cluster yaml in the task itself

  eksctlYml:
    - task: eksctlYml
      in:
        clusterRequest: "${clusterRequest}"
        vpcTerraformOutput: "${result.data}"
        configFile: "${clusterRequest.clusterId}-eksctl.yaml"

  eksctlExecution:
    - log: "clusterRequest.builder.version: ${clusterRequest.builder.version}"
    - log: "kubeconfig: ${clusterRequest.kubeconfigFile}"
    - log: "configFile: ${clusterRequest.clusterId}-eksctl.yaml"
    - log: "envars: ${clusterRequest.envars}"

    - try:
      - task: eksctl
        in:
          command: create
          version: "${clusterRequest.builder.version}"
          cluster:
            configFile: "${clusterRequest.clusterId}-eksctl.yaml"
            kubeconfig: "${clusterRequest.kubeconfigFile}"
          envars: ${clusterRequest.envars}
      error:
        - log: ${lastError.cause.message}
        - throw: ${lastError}

  awsClusterDestroy:

    - awsTerraformProcessor

    - task: terraform
      in:
        toolVersion: "${terraformVersion}"
        debug: ${terraformDebug}
        action: plan
        destroy: true
        dir: "${terraformDirectory}"
        stateId: ${clusterRequest.clusterId}
        varFiles:
          - "${workDir}/${terraformDirectory}/00.auto.tfvars.json"

    - if: ${!result.hasChanges}
      then:
        - log: "No changes planned, stopping..."
        - exit

    - form: approvalForm
      fields:
        - plan: { type: "string", readonly: true, value: "${result.output}" }
        - approved: { type: "boolean" }
      values:
        processId: "${txId}"
      yield: true

    - if: ${!approvalForm.approved}
      then:
        - throw: "The plan to destroy was not approved"

    - eksctlDestroy

    - task: terraform
      in:
        toolVersion: "${terraformVersion}"
        debug: ${terraformDebug}
        verbose: ${terraformDebug}
        action: apply
        plan: ${result.planPath}
        stateId: ${clusterRequest.clusterId}
      retry:
        times: 3
        delay: 30

  eksctlDestroy:
    - task: eksctl
      in:
        command: delete
        version: "${clusterRequest.builder.version}"
        cluster:
          name: "${clusterRequest.clusterName}"
          region: "${clusterRequest.region}"
          wait: true
        envars: ${clusterRequest.envars}
      retry:
        times: 3
        delay: 10

  # --------------------------------------------------------------------------------------------------------------------
  # Secrets
  # --------------------------------------------------------------------------------------------------------------------
  # A document with the name of your Concord organization is retrieved from AWS Secrets Manager and are made
  # available to the Concord context via the ${secrets} variable. If you have an element in the document called
  # `adminUsername` it will be available in Concord flows as `${secrets.adminUsername}`.
  # --------------------------------------------------------------------------------------------------------------------

  asmSecrets:
    - try:
      - task: asmSecrets
        in:
          homeRegion: "${clusterRequest.aws.homeRegion}"
          awsAccessKey: "${clusterRequest.aws.accessKey}"
          awsSecretKey: "${clusterRequest.aws.secretKey}"
      error:
        - log: "There is no organizational secrets document. You must create one to continue."
        - log: "${flow}: failed with ${lastError.cause}"
        - throw: "${lastError.cause}"

  asmKubeconfig:
    - task: asmKubeconfig
      in:
        kubeconfigName: "${clusterRequest.kubeconfigName}"
        awsAccessKey: "${clusterRequest.aws.accessKey}"
        awsSecretKey: "${clusterRequest.aws.secretKey}"
        regions:
          - ${clusterRequest.aws.homeRegion}
          - ${clusterRequest.aws.backupRegion}

  asmKubeconfigGet:
    - task: asmKubeconfigGet
      in:
        kubeconfigName: "${clusterRequest.kubeconfigName}"
        awsAccessKey: "${clusterRequest.aws.accessKey}"
        awsSecretKey: "${clusterRequest.aws.secretKey}"
        regions:
          - ${clusterRequest.aws.homeRegion}
          - ${clusterRequest.aws.backupRegion}

  awsIamAuthenticator:
    - task: downloadTools
      in:
        tool: aws-iam-authenticator
